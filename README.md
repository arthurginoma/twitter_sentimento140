# twitter_sentimento140
a small study about the famous dataset sentiment140 | *Data Analytics Bootcamp* – Project 3

<img src="https://t2.tudocdn.net/376633?w=1200&h=1200" width="750">


<br>

## Project Documentation
- [Project Description](#project-description)
- [Goals](#goals)
- [Deliverable files in this repository](#deliverables)
- [Tech](#tech)
- [Dataset](#dataset)

<a name="project-description"></a>

## Project Description

Importante facts about accessibility and public places

```

▫️ The dataset Sentiment140 can be found in 
[Kegle] (https://www.kaggle.com/datasets/kazanova/sentiment140)

The original documentation about Sentiment140 can be found here 
http://help.sentiment140.com/

```

<a name="goals"></a>

## Goals

```

▫️ Work with NLTK (Natural Language Toolkit) is a Python library used for natural language processing. 
The library contains various tools for performing common tasks in text processing, such as tokenization, 
lemmatization, part-of-speech tagging, syntactic analysis, semantic analysis, among others.
 It is widely used in research and natural language processing applications and 
is one of the most popular libraries for working with natural language in Python.

▫️ Work with word tokezination -  is a common preprocessing step because many algorithms and techniques 
rely on the input being represented as a sequence of tokens. The goal of word tokenization is to accurately
separate words and handle any punctuation, spaces, or special characters that may be present in the text.

```

<br>

<a name="deliverables"></a>

## Deliverable files in this repository

* Cleaned final dataset (./assets):
   - `planilhafinal.csv`
   - `palavras.csv`


* Data analysis in Jupyter Notebook:
   - `twitte_analysis.ipynb`
 

<br>

<a name="tech"></a>

## Tech

   - Python @ Jupyter Notebook
   - Pandas / Numpy
   - API
   - NKLT 

<br>

<a name="dataset"></a>





